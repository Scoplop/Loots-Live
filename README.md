# ğŸšï¸ Loots&Live - Jeu de Gestion Post-Apocalyptique

**Loots&Live** est une application web de jeu de gestion dans un univers post-apocalyptique inspirÃ© de Fallout. Construisez votre village, gÃ©rez vos PNJ avec IA gÃ©nÃ©rative, partez en missions, et survivez dans le Wasteland !

## ğŸ® CaractÃ©ristiques principales

- ğŸ˜ï¸ **Gestion de village**: Construction de 24 types de bÃ¢timents (Maisons, Forges, Fermes, etc.)
- ğŸ‘¥ **PNJ intelligents**: PersonnalitÃ©s uniques, dialogues gÃ©nÃ©rÃ©s par IA (Ollama), relations complexes
- âš”ï¸ **SystÃ¨me de missions**: 3 types (RÃ©colte, Sauvetage, Exploration) avec 100 niveaux de difficultÃ©
- ğŸ¯ **Combat tactique**: Tour par tour avec formules RPG (Force, DextÃ©ritÃ©, Endurance, etc.)
- ğŸ”¬ **Arbre de recherche**: 40+ technologies en 7 branches
- âš™ï¸ **Ã‰quipement**: 6 raretÃ©s (Commun â†’ Mythique), craft, gÃ©nÃ©ration procÃ©durale
- ğŸŒ **Villages IA**: Diplomatie, commerce, guerres avec 4 villages IA
- ğŸ† **Progression**: 100 niveaux + 10 cycles Prestige
- ğŸ¨ **Interface**: Mobile-first, thÃ¨me post-apocalyptique, vue isomÃ©trique

## ğŸ“‹ PrÃ©requis

- **Python 3.10+** (tÃ©lÃ©charger sur [python.org](https://www.python.org/downloads/))
- **Ollama** (IA pour dialogues PNJ) - [ollama.ai](https://ollama.ai/)
- **Navigateur moderne** (Chrome, Firefox, Edge)

### Installation d'Ollama

```bash
# Windows : TÃ©lÃ©charger et installer depuis ollama.ai
# Puis tÃ©lÃ©charger un modÃ¨le (au choix) :

# ModÃ¨le recommandÃ© (Ã©quilibrÃ©) :
ollama pull qwen2.5:14b

# Ou modÃ¨le lÃ©ger (rapide) :
ollama pull llama3.2:latest

# Ou modÃ¨le premium (meilleur mais lourd) :
ollama pull qwen2.5:32b
```

**ModÃ¨les disponibles dans votre environnement** : qwen2.5:14b, qwen2.5:32b, llama3.2

## ğŸš€ Installation rapide

### MÃ©thode 1 : Scripts Windows automatiques

```bash
# 1. Cloner ou tÃ©lÃ©charger le projet
cd LootsAndLive

# 2. Double-cliquer sur scripts\install_dependencies.bat
# Cela va crÃ©er l'environnement virtuel et installer les dÃ©pendances

# 3. Copier .env.example vers .env et Ã©diter si besoin
copy .env.example .env

# 4. Initialiser la base de donnÃ©es
scripts\init_db.bat

# 5. DÃ©marrer le serveur
scripts\start_server.bat
```

### MÃ©thode 2 : Installation manuelle

```bash
# 1. CrÃ©er l'environnement virtuel
python -m venv venv
venv\Scripts\activate

# 2. Installer les dÃ©pendances
pip install -r requirements.txt

# 3. Configurer l'application
copy .env.example .env
# Ã‰diter .env si besoin (par dÃ©faut, Ã§a fonctionne)

# 4. Initialiser la base de donnÃ©es
python backend\scripts\init_db.py

# 5. Lancer le serveur
uvicorn backend.app.main:app --reload --host 127.0.0.1 --port 8000
```

## ğŸ¯ Utilisation

1. **Ouvrez votre navigateur** : http://127.0.0.1:8000
2. **CrÃ©ez un compte** : Pseudo + Mot de passe
3. **CrÃ©ez votre personnage** : Apparence + Classe + Stats
4. **Jouez !** : Construisez, recrutez, explorez

## ğŸ› ï¸ Scripts utiles

- `scripts\start_server.bat` : DÃ©marre le serveur
- `scripts\stop_server.bat` : ArrÃªte le serveur
- `scripts\restart_server.bat` : RedÃ©marre le serveur
- `scripts\init_db.bat` : (RÃ©)initialise la base de donnÃ©es

## ğŸ“š Documentation

- **[ARCHITECTURE.md](ARCHITECTURE.md)** : Architecture technique complÃ¨te
- **[DATABASE.md](DATABASE.md)** : SchÃ©ma de base de donnÃ©es (Ã  venir)
- **[GUIDE_JOUEUR.md](GUIDE_JOUEUR.md)** : Guide du joueur (Ã  venir)
- **[Description.txt](Descritpion.txt)** : SpÃ©cifications dÃ©taillÃ©es (PO)

## ğŸ”§ Configuration avancÃ©e

### Fichier .env

Principales variables :

```env
# Base de donnÃ©es
DATABASE_URL=sqlite+aiosqlite:///./data/lootsandlive.db

# SÃ©curitÃ©
SECRET_KEY=CHANGE_ME  # Important en production !

# Ollama
OLLAMA_ENDPOINT=http://localhost:11434/api/generate
OLLAMA_MODEL=llama3.1:8b
```

### ModÃ¨les IA alternatifs

Vous disposez dÃ©jÃ  de plusieurs modÃ¨les :

```bash
# ModÃ¨le lÃ©ger (2GB, plus rapide)
# DÃ©jÃ  installÃ© : llama3.2:latest

# ModÃ¨le Ã©quilibrÃ© (9GB, recommandÃ©)
# DÃ©jÃ  installÃ© : qwen2.5:14b

# ModÃ¨le premium (19GB, meilleur qualitÃ©)
# DÃ©jÃ  installÃ© : qwen2.5:32b
```

Puis modifier `OLLAMA_MODEL` dans `.env` selon vos prÃ©fÃ©rences.

## ğŸ§ª Tests

```bash
# Activer l'environnement virtuel
venv\Scripts\activate

# Lancer tous les tests
pytest

# Tests avec coverage
pytest --cov=backend --cov-report=html
```

## ğŸ“Š API Documentation

Quand le serveur tourne :
- **Swagger UI** : http://127.0.0.1:8000/docs
- **ReDoc** : http://127.0.0.1:8000/redoc

## ğŸ› DÃ©pannage

### Erreur "Ollama non accessible"

```bash
# VÃ©rifier qu'Ollama est lancÃ© :
ollama serve

# Tester l'API :
curl http://localhost:11434/api/tags
```

### Erreur "Port 8000 dÃ©jÃ  utilisÃ©"

```bash
# ArrÃªter le processus existant :
scripts\stop_server.bat

# Ou utiliser un autre port :
uvicorn backend.app.main:app --port 8001
```

### RÃ©initialiser complÃ¨tement

```bash
# Supprimer la base de donnÃ©es
del data\lootsandlive.db

# RÃ©initialiser
scripts\init_db.bat
```

## ğŸ¤ Contribution

Ce projet est actuellement en dÃ©veloppement solo. Suggestions bienvenues via Issues.

## ğŸ“œ Licence

PropriÃ©taire - Â© 2025 - Tous droits rÃ©servÃ©s

## ğŸ™ Remerciements

- **Ollama** pour l'IA locale
- **FastAPI** pour le framework backend
- **SQLAlchemy** pour l'ORM
- Inspiration : Fallout (Bethesda), Clash of Clans (Supercell)

---

**Version** : 1.0.0-alpha  
**DerniÃ¨re mise Ã  jour** : 2025-11-07  
**DÃ©veloppeur** : GitHub Copilot  
**PO** : Utilisateur LootsAndLive
